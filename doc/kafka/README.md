## Kafka介绍(<a href="http://kafka.apache.org/" target="_blank">Office Site</a>)

### Kafka是一个分布式流平台。什么意思呢？
流平台的三种特性：
* 像消息队列或企业级信息系统一样，发布和订阅流；
* 存数据，支持高容错；
* 及时处理流(消息来了就开始处理消息)。

Kafka主要用于以下2种场合：
* 在系统或应用之间构建实时流管道；
* 构建实时应用。

为了理解Kafka如何处理这些，我们从0开始深入研究Kafka的功能。

首先，理解一些概念：
* Kafka集群模式可以运行在单节点或多节点的服务器（可以跨越多个数据中心）上；
* Kafka是分类存储每条记录的，这个分类称为主题(topics);
* 每行记录由key、value、timestamp组成。

Kafka有四个核心的API:
* The Producer API允许应用发布流记录到一个或多个Kafka的主题；
* The Consumer API允许应用订阅一个或多个Kafka主题，并处理这些记录；
* The Streams API允许应用像流处理器一样，消费一个或多个主题种的输入流，并高效地改变输入流的形式；
* The Connector API允许构建和运行可重用的producer或则consumers，这些应用可以把Kafka主题连接到已存在的应用或系统。例如，一个和关系型database建立连接的connecter，可以捕获一个表的所有改变。

Kafka的server和client是采用简单的、高性能、无语义的TCP协议实现的。这种协议具有版本，并且兼容先有版本。我们也提供各Kafka的Java客户端，当然也有各种语言的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Clients">客户端</a>。

### 主题(Topics)和日志(Logs)
我们先来了解Kafka为流记录提供的抽象概念——主题(topic)。
一个主题(topic)是一个分类，Kafka的每个记录都存于某个分类。Kafka的主题通常是多订阅者的；就是说，一个主题可以有0个或多个消费者同时订阅并消费数据。

每个主题，Kafka集群为之维护了一哥分区日志，内容如下所示：
<img src="./assets/log_anatomy.png"></img>
每个分区是有记录构成的有序的，不可修改的队列，记录来了还会继续追加进到这个结构化的日志里面。这些分区里的记录每个都会有各自的偏移量(offset)，这个标识了所有记录在分区中的位置。
Kafka集群会长时间保留发布的记录(无论记录是否被消费过)——采用了一个可配置的保留周期去限定记录的保持时间。例如，如果保留策略设置成2 days，那么一个记录自从发布的2天后，内部会自动清理这些记录的空间。Kafka性能是高效稳定的，所以长时间运行不是问题。
<img src="./assets/log_consumer.png"></img>
事实上，唯一保留在consumer的元数据是消费日志时的offset。这个offset有consumer控制：通常一个消费者会线性移动它的offset一个个地去读取记录，但事实上，自从位置参数由消费者控制后，消费者可以以任何形式去消费记录。例如，一个消费者重置回一个久的offset去重新处理过去过去的数据，或则跳过一些记录去吃消费现在的记录。

这个特性的结合，意味着Kafka消费者是廉价的——消费者的接入和断开，不会对集群造和其它consumers造成大的影响。例如，你可以用命令行工具"tail"任何topic的内容，并不会影响到已有消费者消费的记录。
日志分区有多个目的。首先，这会允许日志规模增长，这会适合单节点机器。每个独立的分区必须置于各自所属的服务器上，但一个主题会有多个分区去处理任意数量的数据。其次更多关于这点事，分区是平行的。